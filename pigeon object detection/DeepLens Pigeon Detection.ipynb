{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d57974c",
   "metadata": {},
   "source": [
    "# Pigon Object Detection for AWS DeepLens\n",
    "\n",
    "This Jupyter Notebook is based on the AWS Groundtruth Object Detection notebook: https://github.com/aws/amazon-sagemaker-examples/tree/master/ground_truth_labeling_jobs/ground_truth_object_detection_tutorial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8422066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imgaug\n",
    "\n",
    "import boto3\n",
    "import os\n",
    "import cv2\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket = \"deeplens-pigeon-detector-alexlenk\"\n",
    "#base_network = \"resnet-50\"\n",
    "base_network = \"vgg-16\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5786a784",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_manifest_filename_train = 'augmented-manifest-train.manifest' # Replace with the filename for your training data.\n",
    "augmented_manifest_filename_validation = 'augmented-manifest-validation.manifest' # Replace with the filename for your validation data.\n",
    "s3_prefix = 'pigeon-object-detection' # Replace with the S3 prefix where your data files reside.\n",
    "s3_output_path = 's3://{}/output'.format(bucket) # Replace with your desired output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354d667d",
   "metadata": {},
   "source": [
    "**Pictures of Pigons are required and need to be available in the S3 bucket** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b7d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 sync s3://$bucket/input-pics/ ./input-pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "augm = iaa.SomeOf((1, 2),\n",
    "            [\n",
    "                sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
    "                iaa.OneOf([\n",
    "                    iaa.GaussianBlur((0, 3.0)), # blur images with a sigma between 0 and 3.0\n",
    "                    iaa.AverageBlur(k=(2, 7)), # blur image using local means with kernel sizes between 2 and 7\n",
    "                    iaa.MedianBlur(k=(3, 11)), # blur image using local medians with kernel sizes between 2 and 7\n",
    "                ]),\n",
    "                iaa.Sharpen(alpha=(0, 1.0), lightness=(0.75, 1.5)), # sharpen images\n",
    "                iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
    "                # search either for all edges or for directed edges,\n",
    "                # blend the result with the original image using a blobby mask\n",
    "                iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
    "                    iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
    "                    iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
    "                ])),\n",
    "                iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5), # add gaussian noise to images\n",
    "                iaa.OneOf([\n",
    "                    iaa.Dropout((0.01, 0.1), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
    "                    iaa.CoarseDropout((0.03, 0.15), size_percent=(0.02, 0.05), per_channel=0.2),\n",
    "                ]),\n",
    "                iaa.Invert(0.05, per_channel=True), # invert color channels\n",
    "                iaa.Add((-5, 10), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
    "                iaa.AddToHueAndSaturation((-20, 20)), # change hue and saturation\n",
    "                # either change the brightness of the whole image (sometimes\n",
    "                # per channel) or change the brightness of subareas\n",
    "                iaa.OneOf([\n",
    "                    iaa.Multiply((0.5, 1.5), per_channel=0.5),\n",
    "                    iaa.FrequencyNoiseAlpha(\n",
    "                        exponent=(-4, 0),\n",
    "                        first=iaa.Multiply((0.5, 1.5), per_channel=True),\n",
    "                        second=iaa.LinearContrast((0.5, 2.0))\n",
    "                    )\n",
    "                ]),\n",
    "                iaa.LinearContrast((0.5, 1.2), per_channel=0.5), # improve or worsen the contrast\n",
    "                iaa.Grayscale(alpha=(0.0, 1.0)),\n",
    "                #sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
    "                #sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
    "                #sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
    "            ],\n",
    "            random_order=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ee46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_input(img_file, annotations, classes=[]):\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img = mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width  = img.shape[1]\n",
    "        colors = dict()\n",
    "        num_detections = 0\n",
    "        for det in annotations:\n",
    "            #(klass, score, x0, y0, x1, y1) = det\n",
    "            klass = det[\"class_id\"]\n",
    "            x0 = det[\"left\"]\n",
    "            y0 = det[\"top\"]\n",
    "            x1 = (det[\"left\"] + det[\"width\"])\n",
    "            y1 = (det[\"top\"] + det[\"height\"])\n",
    "            \n",
    "            num_detections += 1\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0)\n",
    "            ymin = int(y0)\n",
    "            xmax = int(x1)\n",
    "            ymax = int(y1)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id], linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            print('{}'.format(class_name))\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s}'.format(class_name),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "\n",
    "        print('Number of detections: ' + str(num_detections))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d178eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf aug-input-pics\n",
    "!mkdir aug-input-pics\n",
    "rekognition=boto3.client('rekognition')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket, Prefix=\"input-pics/\")\n",
    "\n",
    "object_of_interest = \"Bird\"\n",
    "\n",
    "manifest_content = []\n",
    "\n",
    "for page in pages:\n",
    "    for obj in page['Contents']:\n",
    "        # process items\n",
    "        if(obj[\"Key\"][-3:] == \"jpg\"):\n",
    "            if(os.path.isfile(obj[\"Key\"])):\n",
    "                response = rekognition.detect_labels(\n",
    "                    Image={\n",
    "                        'S3Object': {\n",
    "                            'Bucket': bucket,\n",
    "                            'Name': obj[\"Key\"]\n",
    "                        }\n",
    "                    },\n",
    "                    MaxLabels=123,\n",
    "                    MinConfidence=0.4\n",
    "                )\n",
    "                #print(response)\n",
    "                image_in = cv2.imread(obj[\"Key\"])\n",
    "                img_width = float(image_in.shape[1])\n",
    "                img_height = float(image_in.shape[0])\n",
    "                \n",
    "                for i in range(10):\n",
    "                    scale_percent = float(random.randint(50, 100))\n",
    "                    width = int(float(img_width) * scale_percent/100)\n",
    "                    height = int(float(img_height) * scale_percent/100)\n",
    "                    dim = (width, height)\n",
    "                    print(dim)\n",
    "                    image = cv2.resize(image_in, dim)\n",
    "                    \n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "                    image = iaa.Sometimes(0.9, augm)(image=image)\n",
    "                    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "                    \n",
    "                    filename = \"aug-\" + obj[\"Key\"] + str(random.randint(0, 99999)).zfill(5) + \".jpg\"\n",
    "                    cv2.imwrite(filename, image)\n",
    "                    \n",
    "                    for label in response[\"Labels\"]:\n",
    "                        if label[\"Name\"] == object_of_interest:\n",
    "                            annotations = []\n",
    "                            for instance in label[\"Instances\"]:\n",
    "                                box = instance[\"BoundingBox\"]\n",
    "                                #print(box)\n",
    "                                annotations.append({\"class_id\": 0, \"left\": int(box[\"Left\"]*width), \"top\": int(box[\"Top\"]*height),\n",
    "                                                                        \"width\": int(box[\"Width\"]*width), \"height\": int(box[\"Height\"]*height)})\n",
    "                            manifest_newline = { \n",
    "                                                    \"source-ref\": \"s3://{}/{}\".format(bucket, filename),\n",
    "                                                    \"bounding-box\":\n",
    "                                                    {\n",
    "                                                        \"image_size\": [{ \"width\": width, \"height\": height, \"depth\":3}],\n",
    "                                                        \"annotations\": annotations\n",
    "                                                    },\n",
    "                                                    \"bounding-box-metadata\":\n",
    "                                                    {\n",
    "                                                        \"objects\":\n",
    "                                                        [\n",
    "                                                            {\"confidence\": instance[\"Confidence\"]/100}\n",
    "                                                        ],\n",
    "                                                        \"class-map\":\n",
    "                                                        {\n",
    "                                                            \"0\": label[\"Name\"]\n",
    "                                                        },\n",
    "                                                        \"type\": \"groundtruth/object-detection\",\n",
    "                                                        \"human-annotated\": \"no\",\n",
    "                                                        \"creation-date\": datetime.datetime.today().isoformat(),\n",
    "                                                        \"job-name\": \"automated-lambda-rekognition-creation-new\"\n",
    "                                                    }\n",
    "                                                }\n",
    "                                \n",
    "                            if random.randint(1,10) > 8:\n",
    "                                visualize_input(filename, manifest_newline[\"bounding-box\"][\"annotations\"], classes=[label[\"Name\"]])\n",
    "\n",
    "                            #manifest_content = manifest_content + json.dumps(manifest_newline)\n",
    "                            manifest_content.append(json.dumps(manifest_newline))\n",
    "\n",
    "    print(manifest_content)\n",
    "    !aws s3 rm s3://$bucket/aug-input-pics\n",
    "    !aws s3 cp ./aug-input-pics s3://$bucket/aug-input-pics --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa64f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data_path = 's3://{}/{}/{}'.format(bucket, s3_prefix, augmented_manifest_filename_train)\n",
    "s3_validation_data_path = 's3://{}/{}/{}'.format(bucket, s3_prefix, augmented_manifest_filename_validation)\n",
    "\n",
    "print(\"Augmented manifest for training data: {}\".format(s3_train_data_path))\n",
    "print(\"Augmented manifest for validation data: {}\".format(s3_validation_data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d77e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(manifest_content)\n",
    "\n",
    "\n",
    "\n",
    "print('Preview of Augmented Manifest File Contents')\n",
    "print('-------------------------------------------')\n",
    "print('\\n')\n",
    "\n",
    "for i in range(2):\n",
    "    print('Line {}'.format(i+1))\n",
    "    print(manifest_content[i])\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "train_split = 0.8\n",
    "num_train = int(train_split * len(manifest_content))\n",
    "num_val = int(len(manifest_content) - num_train)\n",
    "\n",
    "print(\"Training samples: {}\".format(num_train))\n",
    "print(\"Validation samples: {}\".format(num_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "s3_client = boto3.client('s3')   \n",
    "s3_client.put_object(ACL='private',\n",
    "                         #Body='\\n'.join(augmented_manifest_lines_cropped[0:num_train-1]),\n",
    "                         Body='\\n'.join(manifest_content[0:num_train]),\n",
    "                         Bucket=bucket,\n",
    "                         Key=s3_train_data_path.split(bucket)[1][1:])\n",
    "\n",
    "s3_client.put_object(ACL='private',\n",
    "                         #Body='\\n'.join(augmented_manifest_lines_cropped[num_train:]),\n",
    "                         Body='\\n'.join(manifest_content[num_train+1:]),\n",
    "                         Bucket=bucket,\n",
    "                         Key=s3_validation_data_path.split(bucket)[1][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f3375",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_names = [\"source-ref\",\"bounding-box\"] # Replace as appropriate for your augmented manifest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373422f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if attribute_names == [\"source-ref\",\"XXXX\"]:\n",
    "        raise Exception(\"The 'attribute_names' variable is set to default values. Please check your augmented manifest file for the label attribute name and set the 'attribute_names' variable accordingly.\")\n",
    "except NameError:\n",
    "    raise Exception(\"The attribute_names variable is not defined. Please check your augmented manifest file for the label attribute name and set the 'attribute_names' variable accordingly.\")\n",
    "\n",
    "# Create unique job name \n",
    "job_name_prefix = 'groundtruth-augmented-manifest-demo'\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "job_name = job_name_prefix + timestamp\n",
    "num_training_samples = num_train\n",
    "training_image = sagemaker.image_uris.retrieve('object-detection', boto3.Session().region_name, version='latest')\n",
    "print(training_image)\n",
    "\n",
    "training_params = \\\n",
    "{\n",
    "    \"AlgorithmSpecification\": {\n",
    "        \"TrainingImage\": training_image, # NB. This is one of the named constants defined in the first cell.\n",
    "        \"TrainingInputMode\": \"Pipe\"\n",
    "    },\n",
    "    \"RoleArn\": role,\n",
    "    \"OutputDataConfig\": {\n",
    "        \"S3OutputPath\": s3_output_path\n",
    "    },\n",
    "    \"ResourceConfig\": {\n",
    "        \"InstanceCount\": 1,   \n",
    "        \"InstanceType\": \"ml.p3.2xlarge\",\n",
    "        \"VolumeSizeInGB\": 50\n",
    "    },\n",
    "    \"TrainingJobName\": job_name,\n",
    "    \"HyperParameters\": { # NB. These hyperparameters are at the user's discretion and are beyond the scope of this demo.\n",
    "         \"base_network\": base_network,\n",
    "         \"use_pretrained_model\": \"1\",\n",
    "         \"num_classes\": \"1\",\n",
    "         \"mini_batch_size\": \"8\",\n",
    "         \"epochs\": \"150\",\n",
    "         \"learning_rate\": \"0.01\",\n",
    "         \"lr_scheduler_step\": \"120,180\",\n",
    "         \"lr_scheduler_factor\": \"0.1\",\n",
    "         \"optimizer\": \"rmsprop\",\n",
    "         \"momentum\": \"0.9\",\n",
    "         \"weight_decay\": \"0.0005\",\n",
    "         \"overlap_threshold\": \"0.5\",\n",
    "         \"nms_threshold\": \"0.45\",\n",
    "         \"image_shape\": \"512\",\n",
    "         \"label_width\": \"350\",\n",
    "         \"num_training_samples\": str(num_training_samples)\n",
    "    },\n",
    "    \"StoppingCondition\": {\n",
    "        \"MaxRuntimeInSeconds\": 86400\n",
    "    },\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\", # NB. Augmented Manifest\n",
    "                    \"S3Uri\": s3_train_data_path,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"AttributeNames\": attribute_names # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"RecordWrapperType\": \"RecordIO\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"AugmentedManifestFile\", # NB. Augmented Manifest\n",
    "                    \"S3Uri\": s3_validation_data_path,\n",
    "                    \"S3DataDistributionType\": \"FullyReplicated\",\n",
    "                    \"AttributeNames\": attribute_names # NB. This must correspond to the JSON field names in your augmented manifest.\n",
    "                }\n",
    "            },\n",
    "            \"ContentType\": \"application/x-recordio\",\n",
    "            \"RecordWrapperType\": \"RecordIO\",\n",
    "            \"CompressionType\": \"None\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    " \n",
    "print('Training job name: {}'.format(job_name))\n",
    "print('\\nInput Data Location: {}'.format(training_params['InputDataConfig'][0]['DataSource']['S3DataSource']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68e170",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client(service_name='sagemaker')\n",
    "client.create_training_job(**training_params)\n",
    "\n",
    "# Confirm that the training job has started\n",
    "status = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "print('Training job current status: {}'.format(status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingJobStatus = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "SecondaryStatus = client.describe_training_job(TrainingJobName=job_name)['SecondaryStatus']\n",
    "print(TrainingJobStatus, SecondaryStatus)\n",
    "while TrainingJobStatus !='Completed' and TrainingJobStatus!='Failed':\n",
    "    time.sleep(60)\n",
    "    TrainingJobStatus = client.describe_training_job(TrainingJobName=job_name)['TrainingJobStatus']\n",
    "    SecondaryStatus = client.describe_training_job(TrainingJobName=job_name)['SecondaryStatus']\n",
    "    print(TrainingJobStatus, SecondaryStatus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7bf743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db58c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "model_name=\"golfball-object-detection-model\" + timestamp\n",
    "print(model_name)\n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_src = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "model_data = model_src\n",
    "print(model_data)\n",
    "\n",
    "hosting_image = get_image_uri(boto3.Session().region_name, 'object-detection')\n",
    "\n",
    "primary_container = {\n",
    "    'Image': hosting_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "#timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.t2.medium',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))\n",
    "\n",
    "%time\n",
    "import time\n",
    "sagemaker = boto3.client('sagemaker')\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sagemaker.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))\n",
    "\n",
    "\n",
    "EndpointStatus = client.describe_endpoint( EndpointName=endpoint_name )[\"EndpointStatus\"]\n",
    "while EndpointStatus !='InService' and EndpointStatus!='Failed':\n",
    "    time.sleep(10)\n",
    "    EndpointStatus = client.describe_endpoint( EndpointName=endpoint_name )[\"EndpointStatus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "def visualize_detection(img, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        #img = mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width  = img.shape[1]\n",
    "        colors = dict()\n",
    "        num_detections = 0\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            num_detections += 1\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id], linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            print('{},{}'.format(class_name,score))\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "\n",
    "        print('Number of detections: ' + str(num_detections))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae24dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "runtime = boto3.client(service_name='runtime.sagemaker')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#image_shape = 300\n",
    "#filename = \"resize-frame.jpg\"\n",
    "filename = \"maxresdefault.jpg\"\n",
    "#filename = \"frame200.jpeg\"\n",
    "image = cv2.imread(filename)\n",
    "#image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#x_start = 700\n",
    "#x_stop = 1600\n",
    "#y_start = 200\n",
    "#y_stop = 1000\n",
    "\n",
    "#image = image[y_start:y_stop, x_start:x_stop]\n",
    "scale_percent = 50\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "#width = int((x_stop-x_start) * scale_percent / 100)\n",
    "#height = int((y_stop-y_start) * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "\n",
    "print(dim)\n",
    "\n",
    "image = cv2.resize(image,dim)\n",
    "cv2.imwrite(\"resized-\" + filename, image)\n",
    "\n",
    "#b = ''\n",
    "#with open(\"resized-\" + filename, 'rb') as image:\n",
    "#    f = image.read()\n",
    "#    b = bytearray(f)\n",
    "    \n",
    "b = bytearray(cv2.imencode('.jpg', image)[1].tostring())\n",
    "\n",
    "endpoint_response = runtime.invoke_endpoint(\n",
    "                                 EndpointName=endpoint_name,\n",
    "                                 ContentType='image/jpeg',\n",
    "                                 Body=b)\n",
    "results    = endpoint_response['Body'].read()\n",
    "detections = json.loads(results)\n",
    "#print(results)\n",
    "\n",
    "visualize_detection(image,\n",
    "                    detections['prediction'],\n",
    "                    [\"Pigeon\"], 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba02801",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = 512\n",
    "#!pip install 'mxnet==1.6.0'\n",
    "\n",
    "#!rm -rf incubator-mxnet\n",
    "#!git clone https://github.com/apache/incubator-mxnet --branch \"v1.8.x\"\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "info = sage.describe_training_job(TrainingJobName=job_name)\n",
    "model_src = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "print(model_src)\n",
    "\n",
    "network_id = base_network.replace(\"-\", \"\")\n",
    "network_id = \"resnet50\"\n",
    "if network_id == \"vgg16\":\n",
    "    network_id = \"vgg16_reduced\"\n",
    "model_patched = model_src.replace(\"model.tar.gz\", \"patched_model_\" + network_id + \"_\" + str(image_shape) + \".tar.gz\")\n",
    "model_patched = model_patched.replace(\"s3://\", \"s3://deeplens-\")\n",
    "\n",
    "!rm -rf ./tmp && mkdir ./tmp\n",
    "!aws s3 cp $model_src ./tmp/\n",
    "!cd ./tmp && tar xvfz model.tar.gz\n",
    "!gunzip -c ./tmp/model.tar.gz | tar -C ./tmp -xopf -\n",
    "network_name = \"ssd_\" + str(network_id) + \"_\" + str(image_shape)\n",
    "print(network_name)\n",
    "!mv ./tmp/*-0000.params ./tmp/$network_name-0000.params\n",
    "!mv ./tmp/*-symbol.json ./tmp/$network_name-symbol.json\n",
    "\n",
    "!python ./incubator-mxnet/example/ssd/deploy.py --network $network_id --data-shape $image_shape --num-class 1 --prefix tmp/ssd_\n",
    "\n",
    "!rm ./tmp/ssd_* && rm ./tmp/model.tar.gz\n",
    "!tar -cvzf ./patched_model.tar.gz -C tmp ./deploy_$network_name-0000.params ./deploy_$network_name-symbol.json ./hyperparams.json\n",
    "#!aws s3 cp patched_model.tar.gz $model_patched\n",
    "out_name = \"s3://{}/patched_model_{}_{}.tar.gz\".format(bucket, network_id, image_shape)\n",
    "!aws s3 cp patched_model.tar.gz $out_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_output = []\n",
    "cloud_output.append({\"test\": \"test\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cloud_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f09051",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
